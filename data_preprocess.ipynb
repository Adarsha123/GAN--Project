{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ae0451-7e64-45e4-bef9-34792717f5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e652799-c79d-439a-8e76-787c30dddfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_folder = '/ihome/lshangguan/adr121/Hearables/data_new/clean_train_dataset'\n",
    "noisy_train_folder = '/ihome/lshangguan/adr121/Hearables/data_new/noisy_train_dataset'\n",
    "acc_train_folder = '/ihome/lshangguan/adr121/Hearables/data_new/acc_train_dataset'\n",
    "\n",
    "clean_val_folder ='/ihome/lshangguan/adr121/Hearables/data_new/clean_val_dataset'\n",
    "noisy_val_folder ='/ihome/lshangguan/adr121/Hearables/data_new/noisy_val_dataset'\n",
    "acc_val_folder ='/ihome/lshangguan/adr121/Hearables/data_new/acc_val_dataset'\n",
    "\n",
    "\n",
    "clean_test_folder = '/ihome/lshangguan/adr121/Hearables/data_new/clean_test_dataset'\n",
    "noisy_test_folder = '/ihome/lshangguan/adr121/Hearables/data_new/noisy_test_dataset'\n",
    "acc_test_folder = '/ihome/lshangguan/adr121/Hearables/data_new/acc_test_dataset'\n",
    "\n",
    "\n",
    "\n",
    "serialized_train_folder = '/ix/lshangguan/adr121/serialized_train_data'\n",
    "serialized_val_folder = '/ix/lshangguan/adr121/serialized_val_data'\n",
    "serialized_test_folder = '/ix/lshangguan/adr121/serialized_test_data'\n",
    "\n",
    "window_size = 1000  # about 1 second of samples\n",
    "sample_rate = 125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ccdcd19-873c-4b43-a3ff-fff85455efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_signal(file, window_size, stride, sample_rate):\n",
    "    \"\"\"\n",
    "    Helper function for slicing signals\n",
    "    by window size and sample rate with [1-stride] percent overlap (default 50%).\n",
    "    \"\"\"\n",
    "    # pass\n",
    "    df = pd.read_csv(file)\n",
    "    df=df.iloc[:,1:]\n",
    "    # num_rows, num_cols = df.shape\n",
    "    hop = int(window_size * stride)\n",
    "    slices = []\n",
    "    for end_idx in range(window_size, len(df), hop):\n",
    "        start_idx = end_idx - window_size\n",
    "        slice_sig = df[start_idx:end_idx]\n",
    "        slices.append(slice_sig)\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b12a0bb-fb7b-453a-870a-1befe0eec5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_serialize(data_type):\n",
    "    stride=0.5\n",
    "    if data_type=='train':\n",
    "        clean_folder = clean_train_folder\n",
    "        noisy_folder = noisy_train_folder\n",
    "        acc_folder = acc_train_folder\n",
    "        serialized_folder = serialized_train_folder\n",
    "    elif data_type=='val':\n",
    "        clean_folder = clean_val_folder\n",
    "        noisy_folder = noisy_val_folder\n",
    "        acc_folder = acc_val_folder\n",
    "        serialized_folder = serialized_val_folder\n",
    "    else:\n",
    "        clean_folder = clean_test_folder\n",
    "        noisy_folder = noisy_test_folder\n",
    "        acc_folder = acc_test_folder\n",
    "        serialized_folder = serialized_test_folder\n",
    "    if not os.path.exists(serialized_folder):\n",
    "        os.makedirs(serialized_folder)\n",
    "    clean_files = glob.glob(clean_folder+\"/*.csv\")\n",
    "    noisy_files = glob.glob(noisy_folder+\"/*.csv\")\n",
    "    acc_files = glob.glob(acc_folder+\"/*.csv\")\n",
    "\n",
    "    clean_files=sorted(clean_files, key=lambda x: int(x.split('_')[-2]))\n",
    "    noisy_files=sorted(noisy_files, key=lambda x: int(x.split('_')[-2]))\n",
    "    # acc_files=sorted(acc_files, key=lambda x: int(x.split('_')[-2]))\n",
    "\n",
    "    acc_file=acc_files[0]\n",
    "\n",
    " \n",
    "    for clean_file,noisy_file in tqdm(zip(clean_files,noisy_files)):\n",
    "    \n",
    "        clean_sliced = slice_signal(clean_file, window_size, stride, sample_rate)\n",
    "        noisy_sliced = slice_signal(noisy_file, window_size, stride, sample_rate)\n",
    "        acc_sliced = slice_signal(acc_file, window_size, stride, sample_rate)\n",
    "        filename = os.path.basename(clean_file).split('.')[0]\n",
    "\n",
    "        for idx, slice_tuple in enumerate(zip(clean_sliced, noisy_sliced,acc_sliced)):\n",
    "            pair = np.array([slice_tuple[0], slice_tuple[1], slice_tuple[2]])\n",
    "            np.save(os.path.join(serialized_folder, '{}_{}'.format(filename, idx+1)), arr=pair)\n",
    "            # np.save(os.path.join(serialized_folder, '{}_{}_acc'.format(filename, idx+1)), arr=acc_sliced)\n",
    "        \n",
    "            # if not os.path.exists(filename[:-5]):\n",
    "            #     os.makedirs(filename[:-5])\n",
    "            # np.save(os.path.join(serialized_folder, '{}_{}'.format(filename, idx)), arr=pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9470e252-c5f0-4c91-9334-999e1c85dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_verify(data_type):\n",
    "    if data_type == 'train':\n",
    "        serialized_folder = serialized_train_folder\n",
    "    elif data_type  == 'val':\n",
    "        serialized_folder = serialized_val_folder\n",
    "    else:\n",
    "        serialized_folder = serialized_test_folder\n",
    "\n",
    "    for root, dirs, files in os.walk(serialized_folder):\n",
    "        files=[f for f in files if not f.startswith('.')]\n",
    "        for filename in tqdm(files, desc='Verifying serialized {} signals'.format(data_type)):\n",
    "            data_pair = np.load(os.path.join(root, filename),allow_pickle=True)\n",
    "            if data_pair.shape[1] != window_size:\n",
    "                print('Snippet length not {} : {} instead'.format(window_size, data_pair.shape[1]))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219b4af-4690-4398-8ae9-2104f32d47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    process_and_serialize('train')\n",
    "    data_verify('train')\n",
    "    process_and_serialize('val')\n",
    "    data_verify('val')\n",
    "    process_and_serialize('test')\n",
    "    data_verify('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
